# GitHub Configuration
GITHUB_TOKEN=ghp_xxxxxxxxxxxxx
GITHUB_WEBHOOK_SECRET=your_webhook_secret_here
GITHUB_REPO=vtanathip/test-case-generator

# Llama 3.2 Configuration (via Ollama)
LLAMA_MODEL=llama3.2:latest
OLLAMA_HOST=http://ollama:11434
OLLAMA_TIMEOUT=120

# ChromaDB Configuration
CHROMADB_HOST=chromadb
CHROMADB_PORT=8000
CHROMADB_COLLECTION=test_cases
CHROMADB_EMBEDDING_MODEL=all-MiniLM-L6-v2

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_IDEMPOTENCY_TTL=3600

# Cloudflare Tunnel Configuration
CLOUDFLARE_TUNNEL_TOKEN=your_tunnel_token_here

# Backend Configuration
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
BACKEND_LOG_LEVEL=INFO
BACKEND_CORS_ORIGINS=http://localhost:3000,https://localhost:3000

# Frontend Configuration
VITE_API_BASE_URL=http://localhost:8000

# Performance Configuration
MAX_CONCURRENT_WEBHOOKS=100
WEBHOOK_TIMEOUT=10
AI_GENERATION_TIMEOUT=120
VECTOR_QUERY_TIMEOUT=5
GITHUB_API_TIMEOUT=30

# Feature Flags
ENABLE_VECTOR_CONTEXT=true
ENABLE_IDEMPOTENCY_CACHE=true
ENABLE_METRICS=true

# Development
DEBUG=false
TESTING=false
